<component name="ProjectRunConfigurationManager">
  <configuration default="false" name="[Apache Spark on Azure Synapse] LogQuery" type="ArcadiaOnSparkConfiguration" factoryName="Spark On Arcadia" nameIsGenerated="true">
    <module name="task10_scala" />
    <spark-job-configuration>
      <local-run>
        <spark-local-run-configurable-model>
          <option name="classpathModifications">
            <list />
          </option>
          <is-parallel-execution>false</is-parallel-execution>
          <is-pass-parent-envs>true</is-pass-parent-envs>
          <program-parameters />
          <working-directory>file://$PROJECT_DIR$</working-directory>
          <envs>
            <map>
              <envs key="HADOOP_HOME" value="C:\hadooplocal" />
            </map>
          </envs>
          <vm-parameters />
          <main-class>sample.LogQuery</main-class>
          <classpath-module>task10_scala</classpath-module>
          <data-root>file://$PROJECT_DIR$/data</data-root>
        </spark-local-run-configurable-model>
      </local-run>
      <focused-tab-index>0</focused-tab-index>
      <spark_submission artifact_name="task10_scala_DefaultArtifact" cluster_mapped_id="" is_local_artifact="false" job_name="[Apache Spark on Azure Synapse] LogQuery" local_artifact_path="" classname="sample.LogQuery" spark_app_type="None">
        <cmd_line_args />
        <jobConfigs>
          <array>
            <option value="driverMemory" />
            <option value="4G" />
          </array>
          <array>
            <option value="driverCores" />
            <option value="1" />
          </array>
          <array>
            <option value="executorMemory" />
            <option value="4G" />
          </array>
          <array>
            <option value="executorCores" />
            <option value="1" />
          </array>
          <array>
            <option value="numExecutors" />
            <option value="5" />
          </array>
        </jobConfigs>
        <ref_files />
        <ref_jars />
        <ssh_cert auth_type="UsePassword" private_key_path="" user="sshuser" remote_debug_enabled="false">
          <option name="draft" value="" />
        </ssh_cert>
        <job_upload_storage upload_path="&lt; Invalid upload path &gt;" />
      </spark_submission>
    </spark-job-configuration>
    <method v="2">
      <option name="Make" enabled="true" />
    </method>
  </configuration>
</component>